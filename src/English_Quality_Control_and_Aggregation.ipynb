{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_Quality_Control_and_Aggregation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkjZfChgUkKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# NOTE: Quality control and aggregation are done concurrently in the code. Quality control and aggregation sections will be labeled with comments."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEbv9toWVbRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quality Control and Aggregation Part 1 English\n",
        "def english_urls_1(english_pass_1, english_pass_1_qual):\n",
        "    #Quality Control finding workers who passed qualification test and didn't pass the test\n",
        "    good_workers = {}\n",
        "    bad_workers = {}\n",
        "    for index, row in english_pass_1_qual.iterrows():\n",
        "        if row['Answer.1. Who is ______ Marina or Sachiko?'] == 3 and row['Answer.2. Each of the Olympic athletes ______ for months even years.'] == 3 and row['Answer.3. The hurricane caused ______ damage to the city.'] == 3 and row['Answer.4. Many cultures have special ceremonies to celebrate a person\\'s ______ of passage into adulthood.'] == 2:\n",
        "            good_workers[row['WorkerId']] = [row['Answer.question1'], row['Answer.question2'], row['Answer.question3'], row['Answer.question4']]\n",
        "        else:\n",
        "            bad_workers[row['WorkerId']] = [row['Answer.question1'], row['Answer.question2'], row['Answer.question3'], row['Answer.question4']]\n",
        "    \n",
        "    #Aggregation building a dataframe with following columns:\n",
        "    #worker id, language, word, vocaroo url, empty pronounciations tuple to be populated in pass 3\n",
        "    good_tuples = []\n",
        "    bad_tuples = []\n",
        "    for index, row in english_pass_1.iterrows():\n",
        "        if row['WorkerId'] in good_workers:\n",
        "            demographics = good_workers.get(row['WorkerId'])\n",
        "            for i in range(1, 11):\n",
        "                good_tuples.append((row['WorkerId'], \"English\", row['Input.text' + str(i)], row['Answer.audioRecording' + str(i)], demographics[0], demographics[1], demographics[2], demographics[3], ()))\n",
        "        elif row['WorkerId'] in bad_workers:\n",
        "            demographics = bad_workers.get(row['WorkerId'])\n",
        "            for i in range(1, 11):\n",
        "                bad_tuples.append((row['WorkerId'], \"English\", row['Input.text' + str(i)], row['Answer.audioRecording' + str(i)], demographics[0], demographics[1], demographics[2], demographics[3], ()))\n",
        "    \n",
        "    good_df = pd.DataFrame(good_tuples, columns=('WorkerId', 'Language', 'Word', 'URL', 'Gender', 'Native Language', 'Years Spoken', 'Number of Languages Spoken', 'Pronunciations'))\n",
        "    bad_df = pd.DataFrame(bad_tuples, columns=('WorkerId', 'Language', 'Word', 'URL', 'Gender', 'Native Language', 'Years Spoken', 'Number of Languages Spoken', 'Pronunciations'))\n",
        "    return [good_df, bad_df]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdTlSaCsZWg7",
        "colab_type": "code",
        "outputId": "1dc09c30-e2f5-4fad-e4ac-284f2cb252a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3247
        }
      },
      "source": [
        "english_pass_1 = pd.read_csv('Pass_1_Eng Results.csv')\n",
        "english_pass_1_qual = pd.read_csv('Eng Qual Results.csv')\n",
        "dfs = english_urls_1(english_pass_1, english_pass_1_qual)\n",
        "good_english = dfs[0]\n",
        "bad_english = dfs[1]\n",
        "\n",
        "good_english = good_english.dropna(how='any',axis=0)\n",
        "bad_english = bad_english.dropna(how='any',axis=0)\n",
        "print(bad_english)\n",
        "#english_df.to_csv('english_results.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           WorkerId Language      Word                                 URL  \\\n",
            "0    A25EY8B3SXJ18J  English       the  https://vocaroo.com/i/s0mu1jgnbI2o   \n",
            "1    A25EY8B3SXJ18J  English      find  https://vocaroo.com/i/s0z9a9P3sQnW   \n",
            "2    A25EY8B3SXJ18J  English     earth  https://vocaroo.com/i/s1jkXNeZe4el   \n",
            "3    A25EY8B3SXJ18J  English      face  https://vocaroo.com/i/s0oUNgTah6yr   \n",
            "4    A25EY8B3SXJ18J  English      pull  https://vocaroo.com/i/s0n9tBSqwSdS   \n",
            "5    A25EY8B3SXJ18J  English      fill  https://vocaroo.com/i/s1LP1Ppjh9K9   \n",
            "6    A25EY8B3SXJ18J  English      hope  https://vocaroo.com/i/s0FOJSSlBE9r   \n",
            "7    A25EY8B3SXJ18J  English      flat  https://vocaroo.com/i/s081fiES9f6i   \n",
            "8    A25EY8B3SXJ18J  English     chair  https://vocaroo.com/i/s1fRhPXOOkon   \n",
            "9    A25EY8B3SXJ18J  English   require  https://vocaroo.com/i/s0tUhUJzelAG   \n",
            "10    ACNYYHTK64MJY  English        of  https://vocaroo.com/i/s1lRPe8x1Ody   \n",
            "11    ACNYYHTK64MJY  English       any  https://vocaroo.com/i/s08NY7rvY5pt   \n",
            "12    ACNYYHTK64MJY  English    father  https://vocaroo.com/i/s0mHSMrymToH   \n",
            "13    ACNYYHTK64MJY  English      wood  https://vocaroo.com/i/s0wgvUX4gsJz   \n",
            "14    ACNYYHTK64MJY  English      cold  https://vocaroo.com/i/s0jVi3SFfDV7   \n",
            "15    ACNYYHTK64MJY  English      east  https://vocaroo.com/i/s1PIBwemHHSx   \n",
            "16    ACNYYHTK64MJY  English    flower  https://vocaroo.com/i/s0h7ib9kcw58   \n",
            "17    ACNYYHTK64MJY  English    twenty  https://vocaroo.com/i/s0ce1VsA7hN5   \n",
            "18    ACNYYHTK64MJY  English    danger  https://vocaroo.com/i/s06ITcm5Dkbt   \n",
            "19    ACNYYHTK64MJY  English     broad  https://vocaroo.com/i/s0a7ksBnJMRS   \n",
            "20   A2BLFFZ0VK2WNA  English        in  https://vocaroo.com/i/s0xAaASMbtJD   \n",
            "21   A2BLFFZ0VK2WNA  English      take  https://vocaroo.com/i/s1OIsWll3LNU   \n",
            "22   A2BLFFZ0VK2WNA  English      page  https://vocaroo.com/i/s1Rgj3aRcw7w   \n",
            "23   A2BLFFZ0VK2WNA  English      girl  https://vocaroo.com/i/s08R0kkKqHsO   \n",
            "24   A2BLFFZ0VK2WNA  English     power  https://vocaroo.com/i/s1DpAhTw2PBL   \n",
            "25   A2BLFFZ0VK2WNA  English     grand  https://vocaroo.com/i/s13Ov5PnVYr5   \n",
            "26   A2BLFFZ0VK2WNA  English      jump  https://vocaroo.com/i/s0CFGz1hlOrI   \n",
            "27   A2BLFFZ0VK2WNA  English      hole  https://vocaroo.com/i/s1roUWGyrxbU   \n",
            "28   A2BLFFZ0VK2WNA  English   soldier  https://vocaroo.com/i/s0iwavTUMAET   \n",
            "29   A2BLFFZ0VK2WNA  English    plural  https://vocaroo.com/i/s01rvlvUihK5   \n",
            "..              ...      ...       ...                                 ...   \n",
            "520  A2BLFFZ0VK2WNA  English       may  https://vocaroo.com/i/s1zymWrJ137P   \n",
            "521  A2BLFFZ0VK2WNA  English    mother  https://vocaroo.com/i/s0F9Tt75aW2e   \n",
            "522  A2BLFFZ0VK2WNA  English     horse  https://vocaroo.com/i/s0e3BlUFGI5e   \n",
            "523  A2BLFFZ0VK2WNA  English      road  https://vocaroo.com/i/s0xkdihEB0J2   \n",
            "524  A2BLFFZ0VK2WNA  English      snow  https://vocaroo.com/i/s0FClCiPCitF   \n",
            "525  A2BLFFZ0VK2WNA  English     month  https://vocaroo.com/i/s1qULIl6W77x   \n",
            "526  A2BLFFZ0VK2WNA  English    bottom  https://vocaroo.com/i/s0nnRHESI6tn   \n",
            "527  A2BLFFZ0VK2WNA  English   provide  https://vocaroo.com/i/s0rrow8PGepL   \n",
            "528  A2BLFFZ0VK2WNA  English  molecule  https://vocaroo.com/i/s12m6GJvITeA   \n",
            "529  A2BLFFZ0VK2WNA  English     occur  https://vocaroo.com/i/s1VpEiF5x1Hg   \n",
            "530  A25EY8B3SXJ18J  English      down  https://vocaroo.com/i/s0401GPbYkMC   \n",
            "531  A25EY8B3SXJ18J  English     world  https://vocaroo.com/i/s1TtbKTUO6dg   \n",
            "532  A25EY8B3SXJ18J  English       cut  https://vocaroo.com/i/s13KuCrnlprB   \n",
            "533  A25EY8B3SXJ18J  English       map  https://vocaroo.com/i/s05jTZUlp7F9   \n",
            "534  A25EY8B3SXJ18J  English      tire  https://vocaroo.com/i/s1PHld4EnfCH   \n",
            "535  A25EY8B3SXJ18J  English   million  https://vocaroo.com/i/s1Ec2EjZptR6   \n",
            "536  A25EY8B3SXJ18J  English       key  https://vocaroo.com/i/s0EfFF0xpPIw   \n",
            "537  A25EY8B3SXJ18J  English     agree  https://vocaroo.com/i/s1lrzKVj7bVk   \n",
            "538  A25EY8B3SXJ18J  English    select  https://vocaroo.com/i/s0LoZH0oUvft   \n",
            "539  A25EY8B3SXJ18J  English   support  https://vocaroo.com/i/s1UXXjRzzhSK   \n",
            "540   AIG1UGAMI99Z9  English       now  https://vocaroo.com/i/s0lsdA27EXwj   \n",
            "541   AIG1UGAMI99Z9  English      self  https://vocaroo.com/i/s1N46s5zatWB   \n",
            "542   AIG1UGAMI99Z9  English     color  https://vocaroo.com/i/s1eTvarZD8Q1   \n",
            "543   AIG1UGAMI99Z9  English    govern  https://vocaroo.com/i/s1UPpm3IPAnU   \n",
            "544   AIG1UGAMI99Z9  English   distant  https://vocaroo.com/i/s0JmWm5PPQzo   \n",
            "545   AIG1UGAMI99Z9  English     happy  https://vocaroo.com/i/s0DJUjw6uuhJ   \n",
            "546   AIG1UGAMI99Z9  English     stick  https://vocaroo.com/i/s1HcAwHLNEwS   \n",
            "547   AIG1UGAMI99Z9  English     won't  https://vocaroo.com/i/s1uxy569R7fJ   \n",
            "548   AIG1UGAMI99Z9  English    repeat  https://vocaroo.com/i/s0SBzDQEH9eK   \n",
            "549   AIG1UGAMI99Z9  English     range  https://vocaroo.com/i/s1GA0idwaVte   \n",
            "\n",
            "     Gender Native Language Years Spoken Number of Languages Spoken  \\\n",
            "0         1               O            O                          2   \n",
            "1         1               O            O                          2   \n",
            "2         1               O            O                          2   \n",
            "3         1               O            O                          2   \n",
            "4         1               O            O                          2   \n",
            "5         1               O            O                          2   \n",
            "6         1               O            O                          2   \n",
            "7         1               O            O                          2   \n",
            "8         1               O            O                          2   \n",
            "9         1               O            O                          2   \n",
            "10        1               E            O                          1   \n",
            "11        1               E            O                          1   \n",
            "12        1               E            O                          1   \n",
            "13        1               E            O                          1   \n",
            "14        1               E            O                          1   \n",
            "15        1               E            O                          1   \n",
            "16        1               E            O                          1   \n",
            "17        1               E            O                          1   \n",
            "18        1               E            O                          1   \n",
            "19        1               E            O                          1   \n",
            "20        1               E            O                          2   \n",
            "21        1               E            O                          2   \n",
            "22        1               E            O                          2   \n",
            "23        1               E            O                          2   \n",
            "24        1               E            O                          2   \n",
            "25        1               E            O                          2   \n",
            "26        1               E            O                          2   \n",
            "27        1               E            O                          2   \n",
            "28        1               E            O                          2   \n",
            "29        1               E            O                          2   \n",
            "..      ...             ...          ...                        ...   \n",
            "520       1               E            O                          2   \n",
            "521       1               E            O                          2   \n",
            "522       1               E            O                          2   \n",
            "523       1               E            O                          2   \n",
            "524       1               E            O                          2   \n",
            "525       1               E            O                          2   \n",
            "526       1               E            O                          2   \n",
            "527       1               E            O                          2   \n",
            "528       1               E            O                          2   \n",
            "529       1               E            O                          2   \n",
            "530       1               O            O                          2   \n",
            "531       1               O            O                          2   \n",
            "532       1               O            O                          2   \n",
            "533       1               O            O                          2   \n",
            "534       1               O            O                          2   \n",
            "535       1               O            O                          2   \n",
            "536       1               O            O                          2   \n",
            "537       1               O            O                          2   \n",
            "538       1               O            O                          2   \n",
            "539       1               O            O                          2   \n",
            "540       1               E            O                          O   \n",
            "541       1               E            O                          O   \n",
            "542       1               E            O                          O   \n",
            "543       1               E            O                          O   \n",
            "544       1               E            O                          O   \n",
            "545       1               E            O                          O   \n",
            "546       1               E            O                          O   \n",
            "547       1               E            O                          O   \n",
            "548       1               E            O                          O   \n",
            "549       1               E            O                          O   \n",
            "\n",
            "    Pronunciations  \n",
            "0               ()  \n",
            "1               ()  \n",
            "2               ()  \n",
            "3               ()  \n",
            "4               ()  \n",
            "5               ()  \n",
            "6               ()  \n",
            "7               ()  \n",
            "8               ()  \n",
            "9               ()  \n",
            "10              ()  \n",
            "11              ()  \n",
            "12              ()  \n",
            "13              ()  \n",
            "14              ()  \n",
            "15              ()  \n",
            "16              ()  \n",
            "17              ()  \n",
            "18              ()  \n",
            "19              ()  \n",
            "20              ()  \n",
            "21              ()  \n",
            "22              ()  \n",
            "23              ()  \n",
            "24              ()  \n",
            "25              ()  \n",
            "26              ()  \n",
            "27              ()  \n",
            "28              ()  \n",
            "29              ()  \n",
            "..             ...  \n",
            "520             ()  \n",
            "521             ()  \n",
            "522             ()  \n",
            "523             ()  \n",
            "524             ()  \n",
            "525             ()  \n",
            "526             ()  \n",
            "527             ()  \n",
            "528             ()  \n",
            "529             ()  \n",
            "530             ()  \n",
            "531             ()  \n",
            "532             ()  \n",
            "533             ()  \n",
            "534             ()  \n",
            "535             ()  \n",
            "536             ()  \n",
            "537             ()  \n",
            "538             ()  \n",
            "539             ()  \n",
            "540             ()  \n",
            "541             ()  \n",
            "542             ()  \n",
            "543             ()  \n",
            "544             ()  \n",
            "545             ()  \n",
            "546             ()  \n",
            "547             ()  \n",
            "548             ()  \n",
            "549             ()  \n",
            "\n",
            "[550 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52382aQqZYea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quality Control and Aggregation Part 2 English\n",
        "def english_urls_2(pass2, good_english, bad_english):\n",
        "    #Quality Contol, giving each URL a score. Score is incremented by 1 when it is labeled quality and decremented by 1 when it is labeled bad quality\n",
        "    good_urls = good_english['URL'].tolist()\n",
        "    d = dict.fromkeys(good_urls, 0)\n",
        "    for index, row in pass2.iterrows():\n",
        "        if row['Answer.question0.1']:\n",
        "            for i in range(1, 11):\n",
        "                if row['Input.url' + str(i)] in d:\n",
        "                    if row['Answer.question' + str(i) + '.1']:\n",
        "                        d[row['Input.url' + str(i)]] += 1\n",
        "                    else:\n",
        "                        d[row['Input.url' + str(i)]] -= 1\n",
        "                        \n",
        "    bad_urls = bad_english['URL'].tolist()\n",
        "    d1 = dict.fromkeys(bad_urls, 0)\n",
        "    for index, row in pass2.iterrows():\n",
        "        if row['Answer.question0.1']:\n",
        "            for i in range(1, 11):\n",
        "                if row['Input.url' + str(i)] in d1:\n",
        "                    if row['Answer.question' + str(i) + '.1']:\n",
        "                        d1[row['Input.url' + str(i)]] += 1\n",
        "                    else:\n",
        "                        d1[row['Input.url' + str(i)]] -= 1\n",
        "    \n",
        "    #Aggregation, removing all rows from the origanal dataframes that have URL scores less than 0\n",
        "    for index, row in good_english.iterrows():\n",
        "        if d[row['URL']] < 0:\n",
        "            good_english = good_english.drop(index)\n",
        "            \n",
        "    for index, row in bad_english.iterrows():\n",
        "        if d1[row['URL']] < 0:\n",
        "            bad_english = bad_english.drop(index)\n",
        "            \n",
        "    \n",
        "    return [good_english, bad_english]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaCrDZtznCbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pass2 = pd.read_csv('Pass_2_Eng Results.csv')\n",
        "dfs_2 = english_urls_2(pass2, good_english, bad_english)\n",
        "\n",
        "good_english2 = dfs_2[0]\n",
        "bad_english2 = dfs_2[1]\n",
        "good_english2.to_csv('good_english_results2.csv')\n",
        "bad_english2.to_csv('bad_english_results2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtlCm9EfzV_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quality Control and Aggregation Part 3 English\n",
        "def english_pronunciations(pass3):\n",
        "    for index, row in pass3.iterrows():\n",
        "        # Quality control check: does the user type the correct pronounciation of taxi\n",
        "        if row['Answer.transcription0'].lower() == 'taxi':\n",
        "            #Aggregation: aggregating pronounciations into correct rows in the dataframe\n",
        "            for i in range(1, 11):\n",
        "                url = row['Input.url' + str(i)]\n",
        "                if url in good_english2.URL.values:\n",
        "                    curr_pronunciations = good_english2.loc[good_english2['URL'] == url, 'Pronunciations']\n",
        "                    new = curr_pronunciations + (str(row['Answer.transcription' + str(i)]).lower(),)\n",
        "                    good_english2.loc[good_english2['URL'] == url, 'Pronunciations'] = new\n",
        "                elif url in bad_english2.URL.values:\n",
        "                    curr_pronunciations = bad_english2.loc[bad_english2['URL'] == url, 'Pronunciations']\n",
        "                    new = curr_pronunciations + (str(row['Answer.transcription' + str(i)]).lower(),)\n",
        "                    bad_english2.loc[bad_english2['URL'] == url, 'Pronunciations'] = new\n",
        "\n",
        "\n",
        "    return [good_english2, bad_english2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2goUYg--zXv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pass3 = pd.read_csv('Pass_3_Eng Results.csv')\n",
        "final_dfs = english_pronunciations(pass3)\n",
        "final_english_good = final_dfs[0]\n",
        "final_english_bad = final_dfs[1]\n",
        "\n",
        "final_english_good.to_csv('english_final_good.csv')\n",
        "final_english_bad.to_csv('english_final_bad.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDzpIPuzIigf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creates a chart of words and their mispronunciations\n",
        "\n",
        "words = final_english_bad['Word']\n",
        "pronunciations = final_english_bad['Pronunciations']\n",
        "\n",
        "mispronunciations = []\n",
        "\n",
        "#Create a list of the mispronunciations\n",
        "for index, value in pronunciations.iteritems():\n",
        "    l = list(value)\n",
        "    l = list(dict.fromkeys(l))\n",
        "    if words[index] in l:\n",
        "        l.remove(words[index])\n",
        "    \n",
        "    mispronunciations.append(l)\n",
        "    \n",
        "t = []\n",
        "\n",
        "#Construct a dataframe of words and mispronunciations\n",
        "for i in range(len(mispronunciations)):\n",
        "    t.append((words.iloc[i], mispronunciations[i]))\n",
        "    \n",
        "df = pd.DataFrame(t, columns=('Word', 'Mispronunciations'))\n",
        "df = df[df['Mispronunciations'].map(lambda d: len(d)) > 0]\n",
        "df.to_csv('english_final_bad_mispronunciations.csv')\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}