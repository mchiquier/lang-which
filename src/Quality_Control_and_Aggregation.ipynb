{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quality Control and Aggregation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "nkjZfChgUkKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QG3WPi9hYnRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    pass1 = pd.read_csv('nets213DummyDataFinalCSV1.csv')\n",
        "    number_words_per_hit_firstpass = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEbv9toWVbRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# QUALITY CONTROL PART 1\n",
        "def get_good_urls1(pass1):\n",
        "  number_words_per_hit_firstpass = 1\n",
        "  list_of_urls = []\n",
        "  chosen = pass1.groupby(['chosen','WorkerId'])[\"WorkerId\"].count().reset_index(name=\"count\")\n",
        "  good_workers= chosen[chosen['count'] == 1]['WorkerId'].tolist()\n",
        "   \n",
        "  for i in range(number_words_per_hit_firstpass):\n",
        "    first = pass1['control1_workersChoice'] == pass1['control1_correctAnswer']\n",
        "    second = pass1['control2_workersChoice'] == pass1['control2_correctAnswer']\n",
        "    \n",
        "    output = pass1[first & second]\n",
        "    \n",
        "    output= output[output['WorkerId'].isin(good_workers)]\n",
        "    \n",
        "    list_of_urls = list_of_urls + output['url' + str(i+1)].tolist()\n",
        "    return list_of_urls\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdTlSaCsZWg7",
        "colab_type": "code",
        "outputId": "68a5ebfc-480e-409c-b3cb-f22138d17ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pass1 = pd.read_csv('nets213DummyDataFinalCSV1.csv')\n",
        "ans1 = get_good_urls1(pass1)\n",
        "print(ans1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['vocaroo1.com']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "52382aQqZYea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# QUALITY CONTROL PART 2\n",
        "def get_good_urls2(pass2):\n",
        "    number_words = 1\n",
        "    urls = []\n",
        "    #print(pass2['control_url_correct_answer'])\n",
        "    #print(pass2.loc[pass2.index[0], 'control_url_correct_answer'])\n",
        "    if not pass2.loc[pass2.index[0], 'control_url_correct_answer'] == pass2.loc[pass2.index[0], 'workers_choice']:\n",
        "        return urls\n",
        "    \n",
        "    for i in range(number_words):\n",
        "        if pass2.loc[pass2.index[0], 'choice' + str(i + 1)] == True:\n",
        "            urls.append(pass2.loc[pass2.index[0], 'url' + str(i + 1)])\n",
        "        \n",
        "    return urls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaCrDZtznCbl",
        "colab_type": "code",
        "outputId": "01173504-074c-42a7-9694-ccadda04f87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pass2 = pd.read_csv('nets213DummyDataFinalCSV2.csv')\n",
        "ans2 = get_good_urls2(pass2)\n",
        "print(ans2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['vocaroo1.com']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AtlCm9EfzV_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# QUALITY CONTROL PART \n",
        "def get_good_pronounciations(pass3):\n",
        "    number_words = 1\n",
        "    pronounciations = []\n",
        "    \n",
        "    for i in range(number_words):\n",
        "        pronounciations.append(pass3.loc[pass3.index[0], 'pronounce' + str(i + 1)])\n",
        "        \n",
        "    return pronounciations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2goUYg--zXv1",
        "colab_type": "code",
        "outputId": "92fa7756-1d33-43e6-fd38-b7fe77ec7194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pass3 = pd.read_csv('nets213DummyDataFinalCSV3.csv')\n",
        "ans3 = get_good_pronounciations(pass3)\n",
        "print(ans3)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yfopjZI1Pn1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# AGGREGATION \n",
        "import csv \n",
        "\n",
        "def aggregation(good_url, pronounciation, csv1):\n",
        "  df = pd.read_csv(csv1)\n",
        "  ids = df.WorkerId\n",
        "  languages = df.chosen\n",
        "  genders = df.gender\n",
        "  native_languages = df.native\n",
        "  \n",
        "  with open('Aggregation_Output.csv', 'w') as csvfile:\n",
        "    filewriter = csv.writer(csvfile, delimiter=',',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    for i in range(len(ids)):\n",
        "      filewriter.writerow(['WorkerId', 'Chosen_Language', 'Gender', 'Native_Language'])\n",
        "      filewriter.writerow([ids[i], languages[i], genders[i], native_languages[i]])\n",
        "  \n",
        "  \n",
        "aggregation(ans2, ans3, 'nets213DummyDataFinalCSV1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N2wMjZhpSzaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}