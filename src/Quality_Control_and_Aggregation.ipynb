{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quality_Control_and_Aggregation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "nkjZfChgUkKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# NOTE: Quality control and aggregation are done concurrently in the code. Quality control and aggregation sections will be labeled with comments."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEbv9toWVbRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Quality Control and Aggregation Part 1 English\n",
        "def english_urls_1(english_pass_1, english_pass_1_qual):\n",
        "    #Quality Control finding workers who passed qualification test\n",
        "    good_workers = []\n",
        "    for index, row in english_pass_1_qual.iterrows():\n",
        "        if row['Answer.1. Who is ______ Marina or Sachiko?'] == 3 and row['Answer.2. Each of the Olympic athletes ______ for months even years.'] == 3 and row['Answer.3. The hurricane caused ______ damage to the city.'] == 3 and row['Answer.4. Many cultures have special ceremonies to celebrate a person\\'s ______ of passage into adulthood.'] == 2:\n",
        "            good_workers.append(row['WorkerId'])\n",
        "    \n",
        "    #Aggregation building a dataframe with following columns:\n",
        "    #worker id, language, Male e.g. male = true female = false, word, vocaroo url, empty pronounciations tuple to be populated in pass 3\n",
        "    tuples = []\n",
        "    for index, row in english_pass_1.iterrows():\n",
        "        if row['WorkerId'] in good_workers:\n",
        "            for i in range(1, 11):\n",
        "                tuples.append((row['WorkerId'], \"English\", row['Answer.question1.1'], row['Input.text' + str(i)], row['Answer.audioRecording' + str(i)], ()))\n",
        "    \n",
        "    df = pd.DataFrame(tuples, columns=('WorkerId', 'Language', 'Male', 'Word', 'URL', 'Pronunciations'))\n",
        "    return df\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdTlSaCsZWg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "english_pass_1 = pd.read_csv('eng_pass_1.csv')\n",
        "english_pass_1_qual = pd.read_csv('eng_qual_results.csv')\n",
        "english_df = english_urls_1(english_pass_1, english_pass_1_qual)\n",
        "\n",
        "english_df = english_df.dropna(how='any',axis=0) \n",
        "english_df.to_csv('english_results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52382aQqZYea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Quality Control and Aggregation Part 2 English\n",
        "def english_urls_2(pass2):\n",
        "    #Quality Contol, giving each URL a score. Score is incremented by 1 when it is labeled quality and decremented by 1 when it is labeled bad quality\n",
        "    urls = english_df['URL'].tolist()\n",
        "    d = dict.fromkeys(urls, 0)\n",
        "    for index, row in pass2.iterrows():\n",
        "        if row['Answer.question0.1']:\n",
        "            for i in range(1, 11):\n",
        "                if row['Input.url' + str(i)] in d:\n",
        "                    if row['Answer.question' + str(i) + '.1']:\n",
        "                        d[row['Input.url' + str(i)]] += 1\n",
        "                    else:\n",
        "                        d[row['Input.url' + str(i)]] -= 1\n",
        "    \n",
        "    #Aggregation, removing all rows from the origanal dataframe that have URL scores less than 0\n",
        "    for index, row in english_df.iterrows():\n",
        "        if d[row['URL']] < 0:\n",
        "            english_df.drop(index, inplace = True)\n",
        "    \n",
        "    return english_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaCrDZtznCbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pass2 = pd.read_csv('pass_2.csv')\n",
        "english_2 = english_urls_2(pass2)\n",
        "english_2.to_csv('english_results2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtlCm9EfzV_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Quality Control and Aggregation Part 3 English\n",
        "def english_pronunciations(pass3):\n",
        "    for index, row in pass3.iterrows():\n",
        "        # Quality control check: does the user type the correct pronounciation of taxi\n",
        "        if row['Answer.transcription0'].lower() == 'taxi':\n",
        "            #Aggregation: aggregating pronounciations into correct rows in the dataframe\n",
        "            for i in range(1, 11):\n",
        "                url = row['Input.url' + str(i)]\n",
        "                curr_pronunciations = english_2.loc[english_2['URL'] == url, 'Pronunciations']\n",
        "                #print(curr_pr)\n",
        "                new = curr_pronunciations + (row['Answer.transcription' + str(i)].lower(),)\n",
        "                \n",
        "                english_2.loc[english_2['URL'] == url, 'Pronunciations'] = new\n",
        "\n",
        "\n",
        "    return english_2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2goUYg--zXv1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pass3 = pd.read_csv('pass_3.csv')\n",
        "final_df = english_pronunciations(pass3)\n",
        "final_df.to_csv('english_final_results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qDzpIPuzIigf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creates a chart of words and their mispronunciations\n",
        "\n",
        "words = final_df['Word']\n",
        "pronunciations = final_df['Pronunciations']\n",
        "\n",
        "mispronunciations = []\n",
        "\n",
        "#Create a list of the mispronunciations\n",
        "for index, value in pronunciations.iteritems():\n",
        "    l = list(value)\n",
        "    l = list(dict.fromkeys(l))\n",
        "    if words[index] in l:\n",
        "        l.remove(words[index])\n",
        "    \n",
        "    mispronunciations.append(l)\n",
        "    \n",
        "t = []\n",
        "\n",
        "#Construct a dataframe of words and mispronunciations\n",
        "for i in range(len(mispronunciations)):\n",
        "    t.append((words.iloc[i], mispronunciations[i]))\n",
        "    \n",
        "df = pd.DataFrame(t, columns=('Word', 'Mispronunciations'))\n",
        "df = df[df['Mispronunciations'].map(lambda d: len(d)) > 0]\n",
        "df.to_csv('chart.csv')\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}